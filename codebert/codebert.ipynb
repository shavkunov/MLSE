{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_to_list(df, columns):\n",
    "    return list(zip(*[df[c].to_list() for c in columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_info(path):\n",
    "    files = os.listdir(path)\n",
    "    result = {}\n",
    "    for f in files:\n",
    "        if f[-4:] == \".npy\":\n",
    "            parts = f[:-4].split(\"-\")\n",
    "        else:\n",
    "            parts = f.split(\"-\")\n",
    "        i = int(parts[-1])\n",
    "        start_line = int(parts[-3])\n",
    "        if i in result:\n",
    "            print(\"Conflict!\")\n",
    "        result[i] = (f, start_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface/CodeBERTa-small-v1\", cache_dir='cache/')\n",
    "model = AutoModel.from_pretrained(\"huggingface/CodeBERTa-small-v1\", cache_dir='cache/')\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\", cache_dir='cache2/')\n",
    "#model = AutoModel.from_pretrained(\"microsoft/codebert-base\", cache_dir='cache2/')\n",
    "    \n",
    "model.cuda()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_code(code):\n",
    "    tokenized = tokenizer(code, add_special_tokens=False)\n",
    "    if len(tokenized[\"input_ids\"]) <= 510:\n",
    "        input_ids = [[0] + tokenized[\"input_ids\"] + [2]]\n",
    "        attention_mask = [[1] + tokenized[\"attention_mask\"] + [1]]\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_ids).long().cuda(),\n",
    "            \"attention_mask\": torch.tensor(attention_mask).long().cuda()\n",
    "        }, len(tokenized[\"input_ids\"])\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for i in range(0, len(tokenized[\"input_ids\"]), 510):\n",
    "        if len(tokenized[\"input_ids\"]) >= i + 510:\n",
    "            input_ids.append([0] + tokenized[\"input_ids\"][i:i+510] + [2])\n",
    "            attention_mask.append([1] + tokenized[\"attention_mask\"][i:i+510] + [1])\n",
    "        else:\n",
    "            delta = (i + 510) - len(tokenized[\"input_ids\"])\n",
    "            input_ids.append([0] + tokenized[\"input_ids\"][i:len(tokenized[\"input_ids\"])] + [2] + [1] * delta)\n",
    "            attention_mask.append([1] + tokenized[\"attention_mask\"][i:len(tokenized[\"input_ids\"])] + [1] + [0] * delta)\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids).long().cuda(),\n",
    "        \"attention_mask\": torch.tensor(attention_mask).long().cuda()\n",
    "    }, len(tokenized[\"input_ids\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_part(name):\n",
    "    df = pd.read_csv(f\"data/{name}.csv\")\n",
    "    code_parts = columns_to_list(df, [\"id\", \"methodLoc\", \"startLine\"])\n",
    "    id2file = get_files_info(f\"data/{name}\")\n",
    "    os.makedirs(f\"data/embeddings/{name}\", exist_ok=True)\n",
    "    \n",
    "    for file_id, loc, start_ in tqdm(code_parts, smoothing=0.01):\n",
    "        if math.isnan(loc):\n",
    "            continue\n",
    "        if not file_id in id2file:\n",
    "            continue\n",
    "        filename, start = id2file[file_id]\n",
    "        with open(f\"data/{name}/{filename}\", \"r\") as f:\n",
    "            for _ in range(int(start) - 1):\n",
    "                f.readline()\n",
    "            lines = []\n",
    "            for _ in range(int(loc)):\n",
    "                lines.append(f.readline())\n",
    "        code = \"\\n\".join(lines)\n",
    "        tokenized, l = tokenize_code(code)\n",
    "        with torch.no_grad():\n",
    "            embs = model(**tokenized)[0].cpu().numpy()\n",
    "        embs = embs[:, 0, :]\n",
    "\n",
    "        np.save(f'data/embeddings/{name}/{filename}', embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_part(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_part(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_part(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class EmbeddingCombiner(nn.Module):\n",
    "    def __init__(self, embedding_size=768, hidden_size=512, head_size=128, n_heads=4):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(embedding_size, hidden_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_size, head_size * n_heads)\n",
    "        )\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embedding_size, hidden_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_size, n_heads)\n",
    "        )\n",
    "        self.n_heads = n_heads\n",
    "        self.head_size = head_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if len(x) == 1:\n",
    "            return self.model(x)[0]\n",
    "        x_enc = self.model(x)\n",
    "        x_attn = F.softmax(self.attention(x), dim=0).unsqueeze(-1).expand(-1, self.n_heads, self.head_size).reshape(-1, self.n_heads*self.head_size)\n",
    "        x = (x_enc * x_attn.expand_as(x_enc)).sum(0)\n",
    "        return x\n",
    "    \n",
    "class RegressionNN(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, name, target_name):\n",
    "        df = pd.read_csv(f\"data/{name}_metrics.csv\")\n",
    "        self.code_parts = columns_to_list(df, [\"id\", target_name])\n",
    "        self.id2file = get_files_info(f\"data/embeddings/{name}\")\n",
    "        self.name = name\n",
    "        self.avg_y = np.mean([y for _, y in self.code_parts])\n",
    "        self.std_y = np.std([y for _, y in self.code_parts])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.code_parts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i, y = self.code_parts[idx]\n",
    "        filename, _ = self.id2file[i]\n",
    "        x = np.load(f\"data/embeddings/{self.name}/{filename}\")\n",
    "        return x, y\n",
    "    \n",
    "class MyDataLoader:\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def get_batch(self):\n",
    "        idx = np.random.randint(0, len(self.dataset), self.batch_size)\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for i in idx:\n",
    "            x, y = self.dataset[i]\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "        return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(encoder, regression, dataset, batches, batch_size, norm):\n",
    "    dataloader = MyDataLoader(dataset, batch_size=batch_size)\n",
    "    mae, mse, r2 = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for _ in range(batches):\n",
    "            xs, ys = dataloader.get_batch()\n",
    "            tx = []\n",
    "            for x in xs:\n",
    "                x = torch.tensor(np.array(x), dtype=torch.float32, device=\"cuda\")\n",
    "                tx.append(encoder(x))\n",
    "            xs = torch.stack(tx)\n",
    "            ys_pred = norm[1] * regression(xs).view(-1) + norm[0]\n",
    "            ys = torch.tensor(np.array(ys), dtype=torch.float32, device=\"cuda\")\n",
    "            mse += ((ys_pred - ys)**2).mean().item()\n",
    "            mae += ((ys_pred - ys).abs()).mean().item()\n",
    "            r2 += (1 - ((ys_pred - ys)**2).mean() / ((dataset.avg_y - ys)**2).mean()).item()\n",
    "        mse /= batches\n",
    "        mae /= batches\n",
    "        r2 /= batches\n",
    "    return mse, mae, r2\n",
    "\n",
    "\n",
    "def train_model(target_name, middle_size=512, head_size=128, n_heads=4, hidden_size=256, \n",
    "                lr=1e-4, epoch=90, batch_size=64, batches_per_epoch=1000, batches_per_eval=100):\n",
    "    print(f\"Training model for {target_name} with prarms {(middle_size, head_size, n_heads, hidden_size, lr)}\")\n",
    "    encoder_model = EmbeddingCombiner(768, middle_size, head_size, n_heads)\n",
    "    regression_model = RegressionNN(middle_size, hidden_size)\n",
    "    encoder_model.cuda()\n",
    "    regression_model.cuda()\n",
    "    optim = torch.optim.Adam(list(encoder_model.parameters()) + list(regression_model.parameters()), lr=lr)\n",
    "    \n",
    "    train_dataset = EmbeddingDataset(\"train\", target_name)\n",
    "    test_dataset = EmbeddingDataset(\"test\", target_name)\n",
    "    val_dataset = EmbeddingDataset(\"val\", target_name)\n",
    "\n",
    "    norm = train_dataset.avg_y, train_dataset.std_y\n",
    "    \n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    val_errors = []\n",
    "    for i in range(epoch):\n",
    "        start = time.time()\n",
    "        dataloader = MyDataLoader(train_dataset, batch_size=batch_size)\n",
    "        \n",
    "        print(f\"Epoch {i+1}\")\n",
    "        print(\"Train\")\n",
    "        # Training step\n",
    "        for _ in tqdm(range(batches_per_epoch)):\n",
    "            xs, ys = dataloader.get_batch()\n",
    "            tx = []\n",
    "            for x in xs:\n",
    "                x = torch.tensor(np.array(x), dtype=torch.float32, device=\"cuda\")\n",
    "                tx.append(encoder_model(x))\n",
    "            xs = torch.stack(tx)\n",
    "            ys_pred = regression_model(xs).view(-1)\n",
    "            ys = torch.tensor(np.array(ys), dtype=torch.float32, device=\"cuda\")\n",
    "            ys = (ys - norm[0]) / norm[1]\n",
    "            loss = F.mse_loss(ys_pred, ys)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "        print(\"Test\")\n",
    "        mse, mae, r2 = model_inference(encoder_model, regression_model, train_dataset, batches_per_eval, batch_size, norm)\n",
    "        train_errors.append((mse, mae, r2))\n",
    "        \n",
    "        mse, mae, r2 = model_inference(encoder_model, regression_model, val_dataset, batches_per_eval, batch_size, norm)\n",
    "        val_errors.append((mse, mae, r2))\n",
    "        \n",
    "        mse, mae, r2  = model_inference(encoder_model, regression_model, test_dataset, batches_per_eval, batch_size, norm)\n",
    "        test_errors.append((mse, mae, r2))\n",
    "        print(f\"ERRORS INFO\")\n",
    "        print(f\"Train    | mse: {train_errors[-1][0]}, mae: {train_errors[-1][1]}, r2: {train_errors[-1][2]}\")\n",
    "        print(f\"Validate | mse: {val_errors[-1][0]}, mae: {val_errors[-1][1]}, r2: {val_errors[-1][2]}\")\n",
    "        print(f\"Epoch time: {(time.time() - start) / 60}\")\n",
    "    return train_errors, test_errors, val_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_errors, test_errors, val_errors = train_model(\"methodRfc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_errors, test_errors, val_errors = train_model(\"methodRfc\", middle_size=1024, hidden_size=512, n_heads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_errors, test_errors, val_errors = train_model(\"methodRfc\", middle_size=1024, hidden_size=1024, n_heads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_errors, test_errors, val_errors = train_model(\"methodRfc\", middle_size=256, hidden_size=256, n_heads=4, head_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_errors, test_errors, val_errors = train_model(\"methodRfc\", middle_size=256, hidden_size=128, n_heads=4, head_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_all_metrics(metrics, epoch=50, is_complex=False):\n",
    "    for m in tqdm(metrics):\n",
    "        os.makedirs(f\"logs/{m}\", exist_ok=True)\n",
    "        train_errors, test_errors, val_errors = train_model(m, epoch=epoch, middle_size=1024, hidden_size=1024, n_heads=8, is_complex=is_complex, lr=1e-3, batches_per_epoch=500, batch_size=128)\n",
    "        np.save(f'logs/{m}/train', np.array(train_errors))\n",
    "        np.save(f'logs/{m}/test', np.array(test_errors))\n",
    "        np.save(f'logs/{m}/val', np.array(val_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_metrics = ['methodAnonymousClassesQty', 'methodAssignmentsQty',\n",
    "       'methodCbo', 'methodComparisonsQty', 'methodLambdasQty', 'methodLoc',\n",
    "       'methodLoopQty', 'methodMathOperationsQty', 'methodMaxNestedBlocks',\n",
    "       'methodNumbersQty', 'methodParametersQty', 'methodParenthesizedExpsQty',\n",
    "       'methodReturnQty', 'methodRfc', 'methodStringLiteralsQty',\n",
    "       'methodSubClassesQty', 'methodTryCatchQty', 'methodUniqueWordsQty',\n",
    "       'methodVariablesQty', 'methodWmc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_metrics = ['CyclomaticComplexity', 'HalsteadDifficultyMethod',\n",
    "       'DesignComplexity', 'HalsteadEffortMethod', 'HalsteadVolumeMethod',\n",
    "       'HalsteadBugsMethod', 'HalsteadLengthMethod',\n",
    "       'HalsteadVocabularyMethod', 'EssentialCyclomaticComplexity',\n",
    "       'ControlDensity', 'QCPCorrectness', 'QCPMaintainability',\n",
    "       'QCPReliability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_all_metrics(simple_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_all_metrics(complex_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_plots(metrics):\n",
    "    os.makedirs('logs/plots', exist_ok=True)\n",
    "    for m in metrics:\n",
    "        train_errors = np.load(f'logs/{m}/train.npy')\n",
    "        test_errors = np.load(f'logs/{m}/test.npy')\n",
    "        val_errors = np.load(f'logs/{m}/val.npy')\n",
    "        xs = list(range(len(train_errors)))\n",
    "        \n",
    "        fig, axis = plt.subplots(2, 1, figsize=(8, 8))\n",
    "        axis[0].set_xlim(0, len(train_errors))\n",
    "        axis[0].set_ylim(-1.25, 1.25)\n",
    "        axis[0].grid()\n",
    "        axis[0].set_title(\"R2\")\n",
    "        axis[0].plot(xs, train_errors[:, 2], label=\"Train\", color=(0.8, 0., 0.))\n",
    "        axis[0].plot(xs, val_errors[:, 2], label=\"Validate\", color=(0., 0.8, 0.))\n",
    "        axis[0].plot(xs, test_errors[:, 2], label=\"Test\", color=(0.8, 0.8, 0.))\n",
    "        axis[1].set_xlim(0, len(train_errors))\n",
    "        axis[1].grid()\n",
    "        axis[1].set_title(\"MSE\")\n",
    "        axis[1].plot(xs, train_errors[:, 0], label=\"Train\", color=(0.8, 0., 0.))\n",
    "        axis[1].plot(xs, val_errors[:, 0], label=\"Validate\", color=(0., 0.8, 0.))\n",
    "        axis[1].plot(xs, test_errors[:, 0], label=\"Test\", color=(0.8, 0.8, 0.))\n",
    "        fig.suptitle(f\"{m}\", fontsize=16)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'logs/plots/{m}.jpg')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_plots(simple_metrics)\n",
    "build_plots(complex_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bests(metrics):\n",
    "    os.makedirs('logs/plots', exist_ok=True)\n",
    "    for m in metrics:\n",
    "        #train_errors = np.load(f'logs/{m}/train.npy')\n",
    "        test_errors = np.load(f'logs/{m}/test.npy')\n",
    "        #val_errors = np.load(f'logs/{m}/val.npy')\n",
    "        #xs = list(range(len(train_errors)))\n",
    "        means = np.mean(test_errors[-3:], 0)\n",
    "        print(f\"{m} | R2: {means[2]} | MSE: {means[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_bests(simple_metrics)\n",
    "print_bests(complex_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
