{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import multiprocessing as mp\n",
    "from pathos.multiprocessing import ProcessingPool\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import r2_score as r2, mean_squared_error as mse\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import IterableDataset, Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target metrics {'methodParenthesizedExpsQty', 'QCPReliability', 'HalsteadVocabularyMethod', 'methodSubClassesQty', 'methodVariablesQty', 'ControlDensity', 'methodComparisonsQty', 'HalsteadVolumeMethod', 'HalsteadEffortMethod', 'methodMathOperationsQty', 'methodRfc', 'HalsteadLengthMethod', 'methodNumbersQty', 'methodUniqueWordsQty', 'QCPMaintainability', 'methodLoc', 'methodWmc', 'DesignComplexity', 'methodLambdasQty', 'methodStringLiteralsQty', 'methodAssignmentsQty', 'methodLoopQty', 'HalsteadDifficultyMethod', 'methodCbo', 'methodParametersQty', 'methodAnonymousClassesQty', 'CyclomaticComplexity', 'QCPCorrectness', 'EssentialCyclomaticComplexity', 'methodMaxNestedBlocks', 'HalsteadBugsMethod', 'methodTryCatchQty', 'methodReturnQty'}\n",
      "Total targets 33\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = Path('../samples')\n",
    "EMBEDDINGS_PATH =  DATASET_PATH / 'embeddings'\n",
    "TARGETS_PATH = Path('../target_metrics/snippets')\n",
    "\n",
    "train_metrics = pd.read_csv(TARGETS_PATH / 'train_metrics.csv')\n",
    "#train = pd.read_csv(TARGETS_PATH / 'train.csv')\n",
    "\n",
    "target_metrics = set(train_metrics.columns) - set(['id', 'shortMethodName'])\n",
    "print('Target metrics', target_metrics)\n",
    "print('Total targets', len(target_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 4 µs, total: 8 µs\n",
      "Wall time: 16.7 µs\n"
     ]
    }
   ],
   "source": [
    "def get_raw_data(data_type):\n",
    "    emb_path = EMBEDDINGS_PATH / data_type\n",
    "    chunks = np.array_split(os.listdir(emb_path), mp.cpu_count())\n",
    "    \n",
    "    def process_chunk(files):\n",
    "        data = {}\n",
    "        \n",
    "        for file in files:\n",
    "            file_path = emb_path / file\n",
    "            with open(file_path, 'r') as input_file:\n",
    "                lines = input_file.readlines()\n",
    "\n",
    "            raw_string = ''.join(lines).replace('\\n', '').replace('[', '').replace(']', '')\n",
    "\n",
    "            if 'None' not in raw_string:   \n",
    "                embedding = np.fromstring(raw_string, dtype=np.float, sep='   ')\n",
    "                #embedding = torch.FloatTensor(embedding)\n",
    "            else:\n",
    "                embedding = None\n",
    "                \n",
    "            data[file] = embedding\n",
    "            \n",
    "        return data\n",
    "\n",
    "    with ProcessingPool(mp.cpu_count()) as pool:\n",
    "        proc_chunks = list(pool.map(process_chunk, chunks))\n",
    "    \n",
    "    merged = {}\n",
    "    for dict_chunk in proc_chunks:\n",
    "        merged = {**merged, **dict_chunk}\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, raw_data, data_type, target_metric):\n",
    "        emb_path = EMBEDDINGS_PATH / data_type\n",
    "        path = Path('../samples/') / data_type\n",
    "        self.file2anonfile = {}\n",
    "        for idx, file in enumerate(os.listdir(path)):\n",
    "            self.file2anonfile[file] = f'{data_type}_{idx}'\n",
    "        \n",
    "        self.data = [(file, embedding) for file, embedding in raw_data.items() if embedding is not None]\n",
    "        \n",
    "        target_df = pd.read_csv(TARGETS_PATH / f'{data_type}_metrics.csv')\n",
    "        file_metric_df = target_df[['id', target_metric]]\n",
    "        self.targets = file_metric_df.set_index('id').to_dict()[target_metric]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file, embedding = self.data[index]\n",
    "        anon_file = self.file2anonfile[file]\n",
    "        target = self.targets[anon_file]\n",
    "        \n",
    "        return embedding, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(dataset_full):\n",
    "    X, y = [], []\n",
    "\n",
    "    for index in range(len(dataset_full)):\n",
    "        emb, target = dataset_full[index]\n",
    "        \n",
    "        if target != target: # nan check\n",
    "            continue\n",
    "        \n",
    "        X.append(emb)\n",
    "        y.append(target)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    y = (y - np.mean(y)) / np.std(y)\n",
    "    return torch.FloatTensor(X), torch.FloatTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlp_net = nn.Sequential(\n",
    "            nn.Linear(384, 1), \n",
    "            #nn.ReLU()\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_embedding):\n",
    "        return self.mlp_net(input_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_data = get_raw_data('train')\n",
    "val_raw_data = get_raw_data('val')\n",
    "test_raw_data = get_raw_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating methodParenthesizedExpsQty\n",
      "validating...\n",
      "MSE 1.0852329730987549 R2 -0.08523298852383165\n",
      "EPOCH 1 avg mse loss 1.0919668674468994\n",
      "validating...\n",
      "MSE 1.012900710105896 R2 -0.012900664311151555\n",
      "EPOCH 100 avg mse loss 1.0336980145386976\n",
      "validating...\n",
      "MSE 1.0065199136734009 R2 -0.006519919491435822\n",
      "EPOCH 200 avg mse loss 1.010066397190094\n",
      "validating...\n",
      "MSE 1.0046371221542358 R2 -0.0046371677232848185\n",
      "EPOCH 300 avg mse loss 1.0061129331588745\n",
      "validating...\n",
      "MSE 1.0037156343460083 R2 -0.0037156054949292194\n",
      "EPOCH 400 avg mse loss 1.0044524836540223\n",
      "validating...\n",
      "MSE 1.0031365156173706 R2 -0.0031365148708417667\n",
      "EPOCH 500 avg mse loss 1.0034582602977753\n",
      "validating...\n",
      "MSE 1.0027213096618652 R2 -0.002721328196156003\n",
      "EPOCH 600 avg mse loss 1.0027616226673126\n",
      "validating...\n",
      "MSE 1.0024009943008423 R2 -0.002400983742018248\n",
      "EPOCH 700 avg mse loss 1.0022321486473083\n",
      "validating...\n",
      "MSE 1.002143383026123 R2 -0.002143374929086672\n",
      "EPOCH 800 avg mse loss 1.001810418367386\n",
      "validating...\n",
      "MSE 1.0019313097000122 R2 -0.0019312954588481812\n",
      "EPOCH 900 avg mse loss 1.0014647078514098\n",
      "validating...\n",
      "MSE 1.0017544031143188 R2 -0.0017543962936381607\n",
      "EPOCH 1000 avg mse loss 1.0011759412288666\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "def evaluate(model, features, targets, log_output):\n",
    "    batch_embeddings = features.to(device)\n",
    "    batch_targets = targets.float() \n",
    "\n",
    "    output = model(batch_embeddings).view(-1).cpu().detach().numpy()\n",
    "    mse_error = mse(batch_targets, output)\n",
    "    r2_error = r2(batch_targets, output)\n",
    "        \n",
    "    print(f'MSE {mse_error}', f'R2 {r2_error}')\n",
    "    with open('test_results.txt', 'a') as logs:\n",
    "        logs.write(f'MLP {log_output} MSE {mse_error} R2 {r2_error}\\n')\n",
    "        \n",
    "\n",
    "for target_metric in target_metrics:\n",
    "    print(\"Evaluating\", target_metric)\n",
    "    with open('test_results.txt', 'a') as logs:\n",
    "        logs.write(f'MLP Evaluating {target_metric}\\n')\n",
    "    train_full = FullDataset(train_raw_data, 'train', target_metric)\n",
    "    val_full = FullDataset(val_raw_data, 'val', target_metric)\n",
    "    test_full = FullDataset(test_raw_data, 'test', target_metric)\n",
    "    \n",
    "    X_train, y_train = collect_data(train_full)\n",
    "    X_val, y_val = collect_data(val_full)\n",
    "    X_test, y_test = collect_data(test_full)\n",
    "    mlp = MLP()\n",
    "    \n",
    "    mlp.to(device)\n",
    "    optimizer = SGD(mlp.parameters(), lr=1e-1) # or Adam\n",
    "    start_time = datetime.now()\n",
    "    total_loss = 0.\n",
    "    total_epochs = 0\n",
    "    for epoch in range(1000):\n",
    "\n",
    "        batch_embeddings = X_train.to(device)\n",
    "        batch_targets = y_train.float().to(device)\n",
    "        output = mlp(batch_embeddings).view(-1)\n",
    "        loss = F.mse_loss(output, batch_targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        total_loss += loss.item()\n",
    "        total_epochs += 1\n",
    "\n",
    "        if (epoch + 1) % 100 == 0 or epoch == 0:\n",
    "            print('validating...')\n",
    "            evaluate(mlp, X_val, y_val, 'validate')\n",
    "            print(f'EPOCH {epoch + 1} avg mse loss', total_loss / total_epochs)\n",
    "            total_loss = 0.\n",
    "            total_epochs = 0\n",
    "    break\n",
    "    print('testing', datetime.now() - start_time)\n",
    "    evaluate(mlp, X_test, y_test, 'test')\n",
    "    with open('test_results.txt', 'a') as logs:\n",
    "        logs.write(f'==================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1612,  0.3412, -0.1612, -0.1612, -0.1612, -0.1612, -0.1612, -0.1612,\n",
      "        -0.1612, -0.1612], device='cuda:1')\n",
      "tensor([[ 0.0488],\n",
      "        [ 0.1116],\n",
      "        [ 0.0076],\n",
      "        [-0.0244],\n",
      "        [ 0.0676],\n",
      "        [ 0.0484],\n",
      "        [ 0.0487],\n",
      "        [ 0.0037],\n",
      "        [ 0.0025],\n",
      "        [-0.0021]], device='cuda:1', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = X_train[:10].to(device)\n",
    "y = y_train[:10].to(device)\n",
    "\n",
    "print(y)\n",
    "print(mlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_raw_data = get_raw_data('train')\n",
    "#val_raw_data = get_raw_data('val')\n",
    "#test_raw_data = get_raw_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_xgb(X_train, y_train):\n",
    "#     final_params = {}\n",
    "#     final_params['objective'] = 'reg:squarederror'\n",
    "#     final_params['tree_method'] = 'gpu_hist'\n",
    "#     final_params['learning_rate'] = 0.01\n",
    "#     final_params['n_estimators'] = 500\n",
    "#     # final_params['reg_alpha'] = 1\n",
    "#     # final_params['subsample'] = 0.66\n",
    "#     # final_params['colsample_bytree'] = 0.96\n",
    "#     # final_params['max_depth'] = 10\n",
    "#     # final_params['min_child_weight'] = 0.25\n",
    "\n",
    "#     gbdt = xgb.XGBRegressor(**final_params)\n",
    "#     gbdt.fit(X_train, y_train, verbose=True)\n",
    "#     return gbdt\n",
    "\n",
    "# def create_rf(X_train, y_train):\n",
    "#     clf = RandomForestRegressor(n_estimators=500, n_jobs=-1)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     return clf\n",
    "\n",
    "# def create_lasso(X_train, y_train):\n",
    "#     clf = Lasso()\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     return clf\n",
    "\n",
    "# def evaluate_classic_model(model, str_model, features, targets, log_output):\n",
    "#     output = model.predict(features)\n",
    "#     mse_error = mse(targets, output)\n",
    "#     r2_error = r2(targets, output)\n",
    "        \n",
    "#     print(f'MSE {mse_error}', f'R2 {r2_error}')\n",
    "#     with open('test_results_others.txt', 'a') as logs:\n",
    "#         logs.write(f'{str_model} {log_output} MSE {mse_error} R2 {r2_error}\\n')\n",
    "\n",
    "# for target_metric in target_metrics:\n",
    "#     print(\"Evaluating\", target_metric)\n",
    "#     with open('test_results_others.txt', 'a') as logs:\n",
    "#         logs.write(f'Evaluating {target_metric}\\n')\n",
    "#     train_full = FullDataset(train_raw_data, 'train', target_metric)\n",
    "#     #val_full = FullDataset('val', target_metric)\n",
    "#     test_full = FullDataset(test_raw_data, 'test', target_metric)\n",
    "    \n",
    "#     X_train, y_train = collect_data(train_full)\n",
    "#     #X_val, y_val = collect_data(val_full)\n",
    "#     X_test, y_test = collect_data(test_full)\n",
    "#     #print('train')\n",
    "#     xgb = create_xgb(X_train, y_train)\n",
    "#     rf = create_rf(X_train, y_train)\n",
    "#     lasso = create_lasso(X_train, y_train)\n",
    "    \n",
    "#     print('testing', datetime.now() - start_time)\n",
    "#     for model, str_model in zip([xgb, rf, lasso], ['xgb', 'rf', 'lasso']):\n",
    "#         evaluate_classic_model(model, str_model, X_test, y_test, 'test')\n",
    "#     with open('test_results_others.txt', 'a') as logs:\n",
    "#         logs.write(f'==================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
