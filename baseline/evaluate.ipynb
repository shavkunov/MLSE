{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = path.join('..', 'data', 'snippets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_set(name, sample=1.0):\n",
    "    labels = {}\n",
    "    not_letter = re.compile('[^a-zA-Z]')\n",
    "    with open(path.join(DATA_DIR, f'{name}_metrics.csv'), 'r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            sample_id, _, values = line.split(',', maxsplit=2)\n",
    "            values = list(map(float, values.split(',')))\n",
    "            if any(math.isnan(x) or math.isinf(x) for x in values):\n",
    "                continue\n",
    "            labels[sample_id] = np.array(values)\n",
    "    snippets = []\n",
    "    tokens = []\n",
    "    metrics = []\n",
    "    for sample_id, values in labels.items():\n",
    "        p = path.join(DATA_DIR, name, sample_id + '.java')\n",
    "        if path.exists(p) and random.random() < sample:\n",
    "            with open(p, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            snippets.append(content)\n",
    "            metrics.append(values)\n",
    "            tokens.append(not_letter.sub(' ', content).lower().split())\n",
    "    return snippets, tokens, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_snippets, val_tokens, val_metrics = load_set('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_snippets, test_tokens, test_metrics = load_set('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snippets, train_tokens, train_metrics = load_set('train', sample=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Counter()\n",
    "for token_list in train_tokens:\n",
    "    for token in token_list:\n",
    "        res[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dict = {p[0]:i for i, p in enumerate(res.most_common(2000))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_bows = np.zeros((len(val_tokens), len(ids_dict)))\n",
    "test_bows = np.zeros((len(test_tokens), len(ids_dict)))\n",
    "train_bows = np.zeros((len(train_tokens), len(ids_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tokens_list in enumerate(train_tokens):\n",
    "    for token in tokens_list:\n",
    "        if token in ids_dict:\n",
    "            train_bows[i][ids_dict[token]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tokens_list in enumerate(test_tokens):\n",
    "    for token in tokens_list:\n",
    "        if token in ids_dict:\n",
    "            test_bows[i][ids_dict[token]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tokens_list in enumerate(val_tokens):\n",
    "    for token in tokens_list:\n",
    "        if token in ids_dict:\n",
    "            val_bows[i][ids_dict[token]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = {'{': 0, '}': 1, '(': 2, ')': 3, '+': 4, '-': 5, '*': 6, '/': 7, '=': 8, ';': 9}\n",
    "val_operators = np.zeros((len(val_tokens), len(operators))) \n",
    "test_operators = np.zeros((len(test_tokens), len(operators))) \n",
    "train_operators = np.zeros((len(train_tokens), len(operators))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, snippet in enumerate(train_snippets):\n",
    "    for op, op_id in operators.items():\n",
    "        train_operators[i][op_id] = snippet.count(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, snippet in enumerate(val_snippets):\n",
    "    for op, op_id in operators.items():\n",
    "        val_operators[i][op_id] = snippet.count(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, snippet in enumerate(test_snippets):\n",
    "    for op, op_id in operators.items():\n",
    "        test_operators[i][op_id] = snippet.count(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.concatenate([train_operators, train_bows], axis=1)\n",
    "val_X = np.concatenate([val_operators, val_bows], axis=1)\n",
    "test_X = np.concatenate([test_operators, test_bows], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = np.stack(train_metrics)\n",
    "val_Y = np.stack(val_metrics)\n",
    "test_Y = np.stack(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_norm = (train_Y - train_Y.mean(axis=0)) / train_Y.std(axis=0)\n",
    "val_Y_norm = (val_Y - val_Y.mean(axis=0)) / val_Y.std(axis=0)\n",
    "test_Y_norm = (test_Y - test_Y.mean(axis=0)) / test_Y.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lens = np.array(list(map(len, train_snippets))).reshape(-1, 1)\n",
    "val_lens = np.array(list(map(len, val_snippets))).reshape(-1, 1)\n",
    "test_lens = np.array(list(map(len, test_snippets))).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, train_X, train_Y, test_X, test_Y, metric):\n",
    "    print('Train...')\n",
    "    model.fit(train_X, train_Y)\n",
    "    print('Predict...')\n",
    "    test_predictions = model.predict(test_X)\n",
    "    print('Calculate score...')\n",
    "    return metric(test_Y, test_predictions), metric(test_Y, test_predictions, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Predict...\n",
      "Calculate score...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.44208609104798957,\n",
       " array([7.61068762e-02, 6.94005355e-01, 2.80624462e-01, 3.34203495e-01,\n",
       "        1.40746686e-02, 8.95268345e-01, 2.43567901e-01, 2.14855650e-01,\n",
       "        2.65480009e-01, 2.51361498e-01, 2.58665038e-02, 1.49099668e-01,\n",
       "        1.25137254e-01, 5.27925782e-01, 3.30161177e-01, 7.70330842e-04,\n",
       "        1.51678772e-01, 5.21410517e-01, 6.64248664e-01, 6.98648390e-01,\n",
       "        7.38339741e-01, 5.41101590e-01, 7.00244957e-01, 3.28643120e-01,\n",
       "        8.18382852e-01, 6.60202653e-01, 8.33354291e-01, 5.79048775e-01,\n",
       "        3.35614765e-01, 6.30580112e-02, 8.18712988e-01, 8.48579991e-01,\n",
       "        8.59061951e-01]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(LinearRegression(), train_lens, train_Y_norm, test_lens, test_Y_norm, r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Predict...\n",
      "Calculate score...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5104502598142987,\n",
       " array([0.0884226 , 0.82122059, 0.29244093, 0.49088157, 0.01375514,\n",
       "        0.89570249, 0.29213439, 0.38420851, 0.30441484, 0.30778025,\n",
       "        0.02112639, 0.18652014, 0.5963828 , 0.5976969 , 0.50491976,\n",
       "        0.00254533, 0.16826764, 0.57438667, 0.70823153, 0.72488866,\n",
       "        0.74878846, 0.59321856, 0.70444302, 0.59358835, 0.82424484,\n",
       "        0.72234906, 0.85329169, 0.64943751, 0.53277937, 0.06461932,\n",
       "        0.84175017, 0.86670749, 0.8737136 ]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(Lasso(), train_X, train_Y_norm, test_X, test_Y_norm, r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Predict...\n",
      "Calculate score...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7598032800360006,\n",
       " array([0.6963369 , 0.91246132, 0.64200707, 0.71207062, 0.29515852,\n",
       "        0.9245143 , 0.80669274, 0.71795378, 0.85827794, 0.53334605,\n",
       "        0.41138909, 0.3589164 , 0.70638757, 0.86520222, 0.65000299,\n",
       "        0.13660258, 0.92235492, 0.84291463, 0.85484911, 0.86680625,\n",
       "        0.8869722 , 0.80884575, 0.86673574, 0.7814857 , 0.89373093,\n",
       "        0.83395654, 0.91541879, 0.89652533, 0.74700369, 0.96306838,\n",
       "        0.9149091 , 0.92246966, 0.92814145]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(RandomForestRegressor(n_jobs=-1), train_X, train_Y_norm, test_X, test_Y_norm, r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Predict...\n",
      "Calculate score...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6217559487830768,\n",
       " array([ 0.62787301,  0.84426504,  0.40664615,  0.47806797, -0.31294398,\n",
       "         0.88671239,  0.59336868,  0.41877129,  0.71912917,  0.28573883,\n",
       "        -0.00213365, -0.15643778,  0.67081743,  0.72573648,  0.4586186 ,\n",
       "         0.11504872,  0.83552408,  0.70696054,  0.76622208,  0.78740209,\n",
       "         0.82016121,  0.71739325,  0.78260562,  0.79495244,  0.81686929,\n",
       "         0.81561499,  0.85921613,  0.79389082,  0.70924798,  0.911963  ,\n",
       "         0.88137491,  0.8732654 ,  0.88600411]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(DecisionTreeRegressor(), train_X, train_Y_norm, test_X, test_Y_norm, r2_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Defaul Python",
   "language": "python",
   "name": "default-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
